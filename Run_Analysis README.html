<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Run_Analysis README</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>





<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h2>Run_Analysis README</h2>

<p>The run_analysis script uses data collected from an experiment measuring smartphone recognition of human activity. The abstract and citation of this experiment are below.</p>

<p>In brief, the data of interest for this script are the subject identifiers (n = 30),  activity labels and names (n = 6), mean and standard deviation variables for each signal (n = 66) and their averages (n = 180). Further description of all variables are available in the codebook.</p>

<p>There are five files in the Getting-Cleaning-Data repository.</p>
<ul>
<li>run_analysis.R: the script used to transform, tidy, and summarise human activity data.</li>
<li>Run_Analysis README.html: this describes the files were used, citation and abstract information, and the variables of interest.</li>
<li>Run_Analysis Codebook.html: this describes the data steps, transformations, and other relevant information.</li>
<li>example_output: this contains snippets of data for a better picture of the final datasets. </li>
<li>dataset_averages.txt: the averages dataset in full.
</ul>

<p>The files used in the script are listed here.</p>
<ul>
<li>features.txt: a set of all features in the database (i.e., used for measure names)</li>
<li>activity_labels.txt: numeric activity labels and their respective names</li>
<li>X_train.txt, X_test.txt: training and test measure data</li>
<li>y_train.txt, y_test.txt: training and test labels (i.e., activity labels)</li>
<li>subject_train.txt, subject_test.txt: training and test subject IDs</li>
</ul>

<p>Abstract: Human Activity Recognition database built from the recordings of 30 subjects performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors.</p>

<p>References</p>

<p>[1] Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. International Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz, Spain. Dec 2012</p>

</body>

</html>
